<!DOCTYPE html><html class="appearance-auto" lang="zh-CN"><head><meta charset="UTF-8"><title>Python数据分析之Pandas-数据文件加载与存储（一）</title><meta name="description"><meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no, initial-scale=1"><link rel="icon" href="/images/favicon.png"><link rel="stylesheet" href="/style/common/bulma.css"><link rel="stylesheet" href="/style/base.css"><link rel="stylesheet" href="/style/common/helper.css"><script src="/js/common.js"></script><link rel="stylesheet" href="/style/post.css"><link rel="stylesheet" href="/style/themes/highlight-theme-light.css"><script src="/js/highlight.pack.js"></script><meta name="generator" content="Hexo 5.3.0"></head><body class="is-flex is-flex-direction-column"><header class="is-flex header-widget is-flex-shrink-0 is-align-items-center is-justify-content-space-between is-hidden-mobile"><section class="is-hidden-mobile is-flex-shrink-0"><h2><a href="/">loannes's blog</a></h2></section><h3 class="is-hidden-mobile is-family-serif is-full-height is-flex is-align-items-center is-flex-shrink-0"><div class="is-full-height" id="postTopic"><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">Python数据分析之Pandas-数据文件加载与存储（一）</p><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">点击返回顶部</p></div></h3><aside class="is-flex-shrink-0"><h3 class="is-inline-block"><a href="/">首页</a></h3><h3 class="is-inline-block"><a href="/about">关于</a></h3><h3 class="is-inline-block"><a href="/archives">归档</a></h3></aside></header><header class="is-flex header-widget is-flex-shrink-0 is-align-items-center is-justify-content-center is-hidden-tablet"><h3 class="is-inline-block"><a href="/">首页</a></h3><h3 class="is-inline-block"><a href="/about">关于</a></h3><h3 class="is-inline-block"><a href="/archives">归档</a></h3></header><main><main class="container is-max-widescreen content section post-page pt-4 px-4"><div class="columns is-flex-desktop is-justify-content-center is-flex-direction-row-reverse"><div class="column is-3 is-hidden-mobile"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%BB%E5%86%99%E6%96%87%E6%9C%AC%E6%A0%BC%E5%BC%8F%E7%9A%84%E6%95%B0%E6%8D%AE"><span class="toc-text">读写文本格式的数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%80%90%E5%9D%97%E8%AF%BB%E5%8F%96%E6%96%87%E6%9C%AC%E6%96%87%E4%BB%B6"><span class="toc-text">逐块读取文本文件</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B0%86%E6%95%B0%E6%8D%AE%E5%86%99%E5%88%B0%E6%96%87%E6%9C%AC%E6%A0%BC%E5%BC%8F%E4%B8%AD"><span class="toc-text">将数据写到文本格式中</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%89%8B%E5%B7%A5%E5%A4%84%E7%90%86%E5%88%86%E9%9A%94%E7%AC%A6%E6%A0%BC%E5%BC%8F"><span class="toc-text">手工处理分隔符格式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#JSON%E6%95%B0%E6%8D%AE"><span class="toc-text">JSON数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%A9%E7%94%A8lxml-objectify%E8%A7%A3%E6%9E%90XML"><span class="toc-text">利用lxml.objectify解析XML</span></a></li></ol></div><div class="column is-9"><header class="my-4"><a href="/tags/Python,%20Pandas,%20%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8"><i class="tag post-item-tag">Python, Pandas, 数据存储</i></a></header><h1 class="mt-0 mb-1 is-family-serif" id="postTitle">Python数据分析之Pandas-数据文件加载与存储（一）</h1><time class="has-text-grey" datetime="2019-04-29T10:30:13.000Z">2019-04-29</time><article class="mt-2 post-content"><p><img src="http://upload-images.jianshu.io/upload_images/1515206-0a0bffaaf9ee20fc.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="pandas-read-file"></p>
<h2 id="读写文本格式的数据"><a href="#读写文本格式的数据" class="headerlink" title="读写文本格式的数据"></a>读写文本格式的数据</h2><p><strong>通过<code>cat</code> 输出文件内容：</strong></p>
<pre><code>In [20]: cat ex1.csv
a,b,c,d,message
1,2,3,4,hello
5,6,7,8,world
9,10,11,12,foo
</code></pre>
<p><strong>由于文件是<code>csv</code>格式，可以使用<code>read_csv</code>读取文件并返回<code>DataFrame</code>：</strong></p>
<pre><code>In [23]: df = pd.read_csv(&#39;ex1.csv&#39;)

In [24]: df
Out[24]:
   a   b   c   d message
0  1   2   3   4   hello
1  5   6   7   8   world
2  9  10  11  12     foo
</code></pre>
<p><strong>如果想读取没有标题行的文件:</strong></p>
<pre><code>In [26]: cat ex2.csv
1,2,3,4,hello
5,6,7,8,world
9,10,11,12,foo

In [27]: pd.read_csv(&#39;ex2.csv&#39;, header=None)
Out[27]:
   0   1   2   3      4
0  1   2   3   4  hello
1  5   6   7   8  world
2  9  10  11  12    foo
</code></pre>
<p><strong>或者可以直接定义标题</strong></p>
<pre><code>In [28]: pd.read_csv(&#39;ex2.csv&#39;, names=[&#39;a&#39;,&#39;b&#39;,&#39;c&#39;,&#39;d&#39;,&#39;message&#39;])
Out[28]:
   a   b   c   d message
0  1   2   3   4   hello
1  5   6   7   8   world
2  9  10  11  12     foo
</code></pre>
<p><strong>还可以将多个列做成层次化索引</strong></p>
<pre><code>In [29]: cat csv_mindex.csv
key1,key2,value1,value2
one,a,1,2
one,b,3,4
one,c,5,6
one,d,7,8
two,e,9,10

In [30]: parsed = pd.read_csv(&#39;csv_mindex.csv&#39;, index_col=[&#39;key1&#39;,&#39;key2&#39;])

In [31]: parsed
Out[31]:
           value1  value2
key1 key2
one  a          1       2
     b          3       4
     c          5       6
     d          7       8
two  e          9      10
</code></pre>
<p><strong>有些表格分隔会比较杂乱，如下面这个:</strong></p>
<pre><code>In [32]: cat ex3.csv
            A              B                C
Aaa -0.264438   -1.026059           -0.619500
bbb 0.927272    0.302904            -0.032399
Ccc -0.265273   -0.386314           -0.217601
</code></pre>
<p><strong>可以在读取的时候传入一个正则来调整这些不规则的分隔</strong></p>
<pre><code>In [32]: cat ex3.csv
            A              B                C
Aaa -0.264438   -1.026059           -0.619500
bbb 0.927272    0.302904            -0.032399
Ccc -0.265273   -0.386314           -0.217601
In [33]: result = pd.read_csv(&#39;ex3.csv&#39;, sep=&#39;\s+&#39;)

In [34]: result
Out[34]:
            A         B         C
Aaa -0.264438 -1.026059 -0.619500
bbb  0.927272  0.302904 -0.032399
Ccc -0.265273 -0.386314 -0.217601
</code></pre>
<p><strong>如何在读取文件的时候找到缺失值并标记为NaN</strong></p>
<pre><code>In [59]: cat ex5.csv
Something,a,b,c,d,message
0,one,1,2,3,4,NA
1,two,5,6,-1.#IND,8,world
2,three,7,8,9,10,NULL

In [57]: result = pd.read_csv(&#39;ex5.csv&#39;)

In [58]: pd.isnull(result)
Out[58]:
   Something      a      b      c      d  message
0      False  False  False  False  False     True
1      False  False  False   True  False    False
2      False  False  False  False  False     True
</code></pre>
<p>pandas默认会把<code>NA</code>,<code>-1.#IND</code>,<code>NULL</code>当做是缺失值。<br>我们也可以自己定义：</p>
<pre><code>In [63]: cat ex5.csv
Something,a,b,c,d,message
0,one,1,2,3,4,NA
1,two,5,6,-1.#IND,8,world
2,three,7,8,9,10,NULL
4,four,11,12,13,14,空
In [64]: result = pd.read_csv(&#39;ex5.csv&#39;)

In [65]: result
Out[65]:
  Something   a   b     c   d message
0       one   1   2   3.0   4     NaN
1       two   5   6   NaN   8   world
2     three   7   8   9.0  10     NaN
4      four  11  12  13.0  14       空  #在这里加了条‘空’的字符串
</code></pre>
<p><strong><code>na_values</code>可以接受一组用于表示缺失值的字符串:</strong></p>
<pre><code>In [61]: result = pd.read_csv(&#39;ex5.csv&#39;, na_values=[&#39;空&#39;])

In [62]: result
Out[62]:
  Something   a   b     c   d message
0       one   1   2   3.0   4     NaN
1       two   5   6   NaN   8   world
2     three   7   8   9.0  10     NaN
4      four  11  12  13.0  14     NaN
</code></pre>
<h2 id="逐块读取文本文件"><a href="#逐块读取文本文件" class="headerlink" title="逐块读取文本文件"></a>逐块读取文本文件</h2><p><strong>如果在处理大型文件的时候，不想直接读取大文件而选择读取部分数据的时候可以通过<code>nrows</code>来读取指定行数</strong></p>
<pre><code>In [69]: pd.read_csv(&#39;ex6.csv&#39;,nrows=5)
Out[69]:
        One       two     three      four key
0  0.467758 -0.758257 -1.824459 -1.824726   L
1 -0.359277 -1.995273  1.252799 -0.853329   B
2 -0.509925  1.259425  0.559245  0.992874   G
3 -0.509925  1.259425  0.559245  0.992874   R
4 -0.509925  1.259425  0.559245  0.992874   Q
</code></pre>
<p><strong>如果想逐块读取行数，可设置chunksize来实现</strong></p>
<pre><code>In [70]: chunker = pd.read_csv(&#39;ex6.csv&#39;,chunksize=5)

In [71]: chunker
Out[71]: &lt;pandas.io.parsers.TextFileReader at 0x117ef4eb8&gt;
</code></pre>
<p>由于<code>read_csv</code>函数返回的是一个<code>TextFileReader</code>对象，所以想获取数据还需要解析它才行。</p>
<pre><code>In [73]: for c in chunker:
    ...:     print(c)
    ...:
        One       two     three      four key
0  0.467758 -0.758257 -1.824459 -1.824726   L
1 -0.359277 -1.995273  1.252799 -0.853329   B
2 -0.509925  1.259425  0.559245  0.992874   G
3 -0.509925  1.259425  0.559245  0.992874   R
4 -0.509925  1.259425  0.559245  0.992874   Q
        One       two     three      four key
5 -0.509925  1.259425  0.559245  0.992874   D
6 -0.509925  1.259425  0.559245  0.992874   A
7 -0.509925  1.259425  0.559245  0.992874   B
8 -0.509925  1.259425  0.559245  0.992874   E
9 -0.509925  1.259425  0.559245  0.992874   C
         One       two     three      four key
10 -0.509925  1.259425  0.559245  0.992874   F
11 -0.509925  1.259425  0.559245  0.992874   M
12 -0.509925  1.259425  0.559245  0.992874   V
</code></pre>
<h2 id="将数据写到文本格式中"><a href="#将数据写到文本格式中" class="headerlink" title="将数据写到文本格式中"></a>将数据写到文本格式中</h2><p><strong>同样数据也可以被输出为分隔符格式的文本，然后存储在文件中</strong><br><strong>我们可以利用<code>DataFrame</code>中的<code>to_csv</code>函数来实现</strong></p>
<pre><code>In [76]: data.to_csv(&#39;ex5out.csv&#39;)

In [77]: cat ex5out.csv
,Something,a,b,c,d,message
0,one,1,2,3.0,4,
1,two,5,6,,8,world
2,three,7,8,9.0,10,
4,four,11,12,13.0,14,空
</code></pre>
<p><strong>当然，也可以使用其他分隔符</strong></p>
<pre><code>In [79]: data.to_csv(&#39;ex5out_02.csv&#39;,sep=&#39;|&#39;)

In [80]: cat ex5out_02.csv
|Something|a|b|c|d|message
0|one|1|2|3.0|4|
1|two|5|6||8|world
2|three|7|8|9.0|10|
4|four|11|12|13.0|14|空
</code></pre>
<h2 id="手工处理分隔符格式"><a href="#手工处理分隔符格式" class="headerlink" title="手工处理分隔符格式"></a>手工处理分隔符格式</h2><p><strong>有时候也会遇到<code>read_csv</code>不能读取的文本，如下面这种：</strong></p>
<pre><code>data = pd.read_csv(&#39;ex7.csv&#39;)
---------------------------------------------------------------------------
ParserError: Error tokenizing data. C error: Expected 3 fields in line 3, saw 4

In [83]: cat ex7.csv
&quot;a&quot;,&quot;b&quot;,&quot;c&quot;
&quot;1&quot;,&quot;2&quot;,&quot;3&quot;
&quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;
</code></pre>
<p><strong>由于数据格式不准确导致无法解析，这个时候就需要用到手动去处理了。通过Python自带的<code>csv.reader</code>来解决此问题：</strong></p>
<pre><code>In [85]: f = open(&#39;ex7.csv&#39;)

In [86]: reader = csv.reader(f)

In [87]: for line in reader:
    ...:     print(line)
    ...:
[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;]
[&#39;1&#39;, &#39;2&#39;, &#39;3&#39;]
[&#39;1&#39;, &#39;2&#39;, &#39;3&#39;, &#39;4&#39;]
</code></pre>
<p>先把数据放进了<code>reader</code>对象中，然后再解决数据不规整的问题：</p>
<pre><code>In [89]: lines = list(csv.reader(open(&#39;ex7.csv&#39;)))
    ...: header, values = lines[0],lines[1:]
    ...: data_dict = &#123;h: v for h, v in zip(header, zip(*values))&#125;
    ...:

In [90]: data_dict
Out[90]: &#123;&#39;a&#39;: (&#39;1&#39;, &#39;1&#39;), &#39;b&#39;: (&#39;2&#39;, &#39;2&#39;), &#39;c&#39;: (&#39;3&#39;, &#39;3&#39;)&#125;
</code></pre>
<p><strong>通过遍历，把<code>reader</code>中的数据按照正确格式放进了字典<code>data_dict</code>中，把不规整的数据给过滤掉了。</strong><br>接下来可以把字典转换成<code>DataFrame</code></p>
<pre><code>In [92]: frame = DataFrame(data_dict)

In [93]: frame
Out[93]:
   a  b  c
0  1  2  3
1  1  2  3
</code></pre>
<h2 id="JSON数据"><a href="#JSON数据" class="headerlink" title="JSON数据"></a>JSON数据</h2><pre><code>In [102]: obj=&quot;&quot;&quot;
     ...: &#123;&quot;name&quot;:&quot;Wes&quot;,
     ...: &quot;places_lived&quot;:[&quot;United States&quot;, &quot;Spain&quot;,&quot;Germany&quot;],
     ...: &quot;pet&quot;:null,
     ...: &quot;siblings&quot;:[&#123;&quot;name&quot;:&quot;Scott&quot;,&quot;age&quot;:25,&quot;pet&quot;:&quot;Zuko&quot;&#125;,
     ...:             &#123;&quot;name&quot;:&quot;Katie&quot;,&quot;age&quot;:33,&quot;pet&quot;:&quot;Cisco&quot;&#125;]
     ...:      &#125;
     ...:      &quot;&quot;&quot;

In [103]: result = json.loads(obj)

In [104]: result
Out[104]:
&#123;&#39;name&#39;: &#39;Wes&#39;,
 &#39;places_lived&#39;: [&#39;United States&#39;, &#39;Spain&#39;, &#39;Germany&#39;],
 &#39;pet&#39;: None,
 &#39;siblings&#39;: [&#123;&#39;name&#39;: &#39;Scott&#39;, &#39;age&#39;: 25, &#39;pet&#39;: &#39;Zuko&#39;&#125;,
  &#123;&#39;name&#39;: &#39;Katie&#39;, &#39;age&#39;: 33, &#39;pet&#39;: &#39;Cisco&#39;&#125;]&#125;
</code></pre>
<p><strong>将JSON对象转换成DataFrame</strong></p>
<pre><code>In [105]: siblings = DataFrame(result[&#39;siblings&#39;], columns=[&#39;name&#39;,&#39;age&#39;])

In [106]: siblings
Out[106]:
    name  age
0  Scott   25
1  Katie   33
</code></pre>
<p>书上记载pandas还未完全开发出能高效导入和导出JSON的功能，需要进一步确认。</p>
<p> ##XML和HTML:Web信息收集<br>利用pandas的<code>read_html</code>来读取html，它会自动结合<code>lxml</code>和<code>Beautiful Soup</code>将数据解析为<code>DataFrame</code>。所以在这之前必须安装好它们。</p>
<pre><code>pip3 install lxml
pip3 install beautifulsoup4 html5lib
</code></pre>
<p><code>read_html</code>会尝试解析<code>&lt;table&gt;</code>标签内的表格数据</p>
<pre><code>In [17]: tables = pd.read_html(&#39;examples/fdic_failed_bank_list.html&#39;)

In [18]: failures = tables[0]

In [19]: failures.head()
Out[19]:
                      Bank Name  ...       Updated Date
0                   Allied Bank  ...  November 17, 2016
1  The Woodbury Banking Company  ...  November 17, 2016
2        First CornerStone Bank  ...  September 6, 2016
3            Trust Company Bank  ...  September 6, 2016
4    North Milwaukee State Bank  ...      June 16, 2016
</code></pre>
<p>接下来可以对数据做一下清洗以及分析，从数据中我们分析下从2000-2010倒闭银行的数量：</p>
<pre><code>In [20]: close_stamps = pd.to_datetime(failures[&#39;Closing Date&#39;]) #把failures[&#39;Closing Date&#39;]全部转换成了DateTime格式放入了Series中

#因为数据中记录了银行的倒闭时间，也就是说知道了‘Closing Date’中有多少个数据就有多少家银行倒闭了。
# 下面以年的形式统计了每年倒闭的银行数
In [21]: close_stamps.dt.year.value_counts()
Out[21]:
2010    157
2009    140
2011     92
2012     51
2008     25
2013     24
2014     18
2002     11
2015      8
2016      5
2004      4
2001      4
2007      3
2003      3
2000      2
Name: Closing Date, dtype: int64
</code></pre>
<h2 id="利用lxml-objectify解析XML"><a href="#利用lxml-objectify解析XML" class="headerlink" title="利用lxml.objectify解析XML"></a>利用lxml.objectify解析XML</h2><p>解析XML将会是一个非常常见的数据分析操作，以后也会经常遇到这种XML文件。<br><strong>我们需要用到<code>lxml</code>库中的<code>objectify</code>对象。</strong></p>
<pre><code>In [24]: path = &#39;Performance_MNR.xml&#39;

In [25]: from lxml import objectify

In [26]: parsed = objectify.parse(open(path))

In [27]: root = parsed.getroot()

In [28]: skip_fields = [&#39;PARENT_SEQ&#39;, &#39;INDICATOR_SEQ&#39;,&#39;DESIRED_CHANGE&#39;,&#39;DECIMAL_PLACES&#39;]

In [29]: for elt in root.INDICATOR:
    ...:     el_data = &#123;&#125;
    ...:     for child in elt.getchildren():
    ...:         if child.tag in skip_fields:
    ...:             continue
    ...:         el_data[child.tag] = child.pyval
    ...:     data.append(el_data)
    ...:

In [30]: perf = DataFrame(data)

In [31]: perf
Out[31]:
              AGENCY_NAME            CATEGORY  ... YTD_ACTUAL YTD_TARGET
0    Metro-North Railroad  Service Indicators  ...       96.9         95
1    Metro-North Railroad  Service Indicators  ...         96         95
2    Metro-North Railroad  Service Indicators  ...       96.3         95
3    Metro-North Railroad  Service Indicators  ...       96.8         95
4    Metro-North Railroad  Service Indicators  ...       96.6         95
5    Metro-North Railroad  Service Indicators  ...       96.2         95
6    Metro-North Railroad  Service Indicators  ...       96.2         95
7    Metro-North Railroad  Service Indicators  ...       96.2         95
8    Metro-North Railroad  Service Indicators  ...       95.9         95
9    Metro-North Railroad  Service Indicators  ...         96         95
10   Metro-North Railroad  Service Indicators  ...       96.1         95
11   Metro-North Railroad  Service Indicators  ...         96         95
12   Metro-North Railroad  Service Indicators  ...       92.6       96.2
13   Metro-North Railroad  Service Indicators  ...       94.6       96.2
14   Metro-North Railroad  Service Indicators  ...       95.4       96.2
15   Metro-North Railroad  Service Indicators  ...       95.9       96.2
16   Metro-North Railroad  Service Indicators  ...       96.2       96.2
17   Metro-North Railroad  Service Indicators  ...       96.4       96.2
18   Metro-North Railroad  Service Indicators  ...       96.5       96.2
19   Metro-North Railroad  Service Indicators  ...       96.4       96.2
20   Metro-North Railroad  Service Indicators  ...       96.3       96.2
21   Metro-North Railroad  Service Indicators  ...       96.2       96.2
22   Metro-North Railroad  Service Indicators  ...       96.1       96.2
23   Metro-North Railroad  Service Indicators  ...         96       96.2
24   Metro-North Railroad  Service Indicators  ...         98       96.3
25   Metro-North Railroad  Service Indicators  ...       95.6       96.3
26   Metro-North Railroad  Service Indicators  ...       96.1       96.3
27   Metro-North Railroad  Service Indicators  ...       96.6       96.3
28   Metro-North Railroad  Service Indicators  ...       96.8       96.3
29   Metro-North Railroad  Service Indicators  ...       96.9       96.3
..                    ...                 ...  ...        ...        ...
618  Metro-North Railroad  Service Indicators  ...      95.14
619  Metro-North Railroad  Service Indicators  ...      95.38
620  Metro-North Railroad  Service Indicators  ...       95.7
621  Metro-North Railroad  Service Indicators  ...         96
622  Metro-North Railroad  Service Indicators  ...      96.21
623  Metro-North Railroad  Service Indicators  ...       96.5
624  Metro-North Railroad  Service Indicators  ...      97.95         97
625  Metro-North Railroad  Service Indicators  ...      98.92         97
626  Metro-North Railroad  Service Indicators  ...      99.29         97
627  Metro-North Railroad  Service Indicators  ...      99.47         97
628  Metro-North Railroad  Service Indicators  ...      99.58         97
629  Metro-North Railroad  Service Indicators  ...      98.19         97
630  Metro-North Railroad  Service Indicators  ...      98.46         97
631  Metro-North Railroad  Service Indicators  ...      98.69         97
632  Metro-North Railroad  Service Indicators  ...       98.3         97
633  Metro-North Railroad  Service Indicators  ...      97.55         97
634  Metro-North Railroad  Service Indicators  ...      97.47         97
635  Metro-North Railroad  Service Indicators  ...      96.84         97
636  Metro-North Railroad  Service Indicators  ...        100         97
637  Metro-North Railroad  Service Indicators  ...        100         97
638  Metro-North Railroad  Service Indicators  ...      98.86         97
639  Metro-North Railroad  Service Indicators  ...      98.76         97
640  Metro-North Railroad  Service Indicators  ...      90.91         97
641  Metro-North Railroad  Service Indicators  ...                    97
642  Metro-North Railroad  Service Indicators  ...                    97
643  Metro-North Railroad  Service Indicators  ...                    97
644  Metro-North Railroad  Service Indicators  ...                    97
645  Metro-North Railroad  Service Indicators  ...                    97
646  Metro-North Railroad  Service Indicators  ...                    97
647  Metro-North Railroad  Service Indicators  ...                    97

[648 rows x 12 columns]
</code></pre>
<p>**我们也可以通过<code>StringIO</code> 来获取<code>HTML</code>的标记<br>下面来看一个简单的例子：</p>
<pre><code>In [33]: from io import StringIO

In [36]: tag = &#39;&lt;a href=&quot;http://www.googlge.com&quot;&gt;Google&lt;/a&gt;&#39;

In [37]: root = objectify.parse(StringIO(tag)).getroot()

In [38]: root.get(&#39;href&#39;)
Out[38]: &#39;http://www.googlge.com&#39;

In [39]: root.text
Out[39]: &#39;Google&#39;
</code></pre>
</article><section class="jump-container is-flex is-justify-content-space-between my-6"><!-- em is empty placeholder--><a class="button is-default" href="/data-analyst/Python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B9%8BPandas-%E6%95%B0%E6%8D%AE%E6%96%87%E4%BB%B6%E5%8A%A0%E8%BD%BD%E4%B8%8E%E5%AD%98%E5%82%A8%EF%BC%88%E4%BA%8C%EF%BC%89/" title="Python数据分析之Pandas-数据文件加载与存储（二）"><i class="iconfont icon-prev mr-2 has-text-grey"></i><span class="has-text-weight-semibold">上一页: Python数据分析之Pandas-数据文件加载与存储（二）</span></a><a class="button is-default" href="/data-analyst/Python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B9%8BPandas-Series%E4%B8%8EDataFrame%E5%9F%BA%E6%9C%AC%E5%8A%9F%E8%83%BD%EF%BC%88%E4%BA%94%EF%BC%89/" title="Python数据分析之Pandas-Series与DataFrame基本功能（五）"><span class="has-text-weight-semibold">下一页: Python数据分析之Pandas-Series与DataFrame基本功能（五）</span><i class="iconfont icon-next ml-2 has-text-grey"></i></a></section><article class="mt-6 comment-container"><script async repo="fuer4869/fuer4869.github.io" src="https://utteranc.es/client.js" issue-term="pathname" theme="preferred-color-scheme"></script></article></div></div></main></main><footer class="is-flex is-flex-direction-column is-align-items-center is-flex-shrink-0 is-family-serif"><section class="sns-container"><a title="twitter" target="_blank" rel="noopener nofollow" href="//twitter.com//"><i class="iconfont icon-twitter"></i></a><!-- Github--><a title="github" target="_blank" rel="noopener nofollow" href="//github.com/fuer4869"><i class="iconfont icon-github"></i></a><!-- Ins--><a title="instagram" target="_blank" rel="noopener nofollow" href="//www.instagram.com//"><i class="iconfont icon-ins"></i></a><!-- RSS--><!-- 知乎--><!-- 领英--><!-- 脸书--><a title="facebook" target="_blank" rel="noopener nofollow" href="//www.facebook.com//"><i class="iconfont icon-tian7_facebook"></i></a></section><p><span>Copyright ©</span><span> loannes 2021</span></p><div class="is-flex is-justify-content-center is-flex-wrap-wrap"><p>Powered by Hexo &verbar;&nbsp;</p><p class="is-flex is-justify-content-center"><a title="Hexo theme author" target="_blank" rel="noopener" href="//github.com/haojen">Theme by Haojen&nbsp;</a></p><div style="margin-top: 2px"><a class="github-button" title="github-button" target="_blank" rel="noopener" href="https://github.com/haojen/hexo-theme-Claudia" data-color-scheme="no-preference: light; light: light; dark: dark;" data-show-count="true"></a></div></div></footer><script async defer src="https://buttons.github.io/buttons.js"></script><script src="/js/post.js"></script></body></html>